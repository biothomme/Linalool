{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ncbi_lumberjack_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biothomme/Linalool/blob/change_research/ncbi_lumberjack_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTz6BHxh85rC",
        "colab_type": "text"
      },
      "source": [
        "#NCBI Lumberjack\n",
        "###Uppsala, Dec 2019\n",
        "This script enables the datamining of the NCBI database for genes in monophyletic groups. Follow the blocks straight forward to gain your result. You can mine x gene entries per Genus/Species of your monophylum and download all sequences in a fasta-file together with 2 informative files:\n",
        "- <b>..._stat.csv:</b> includes all taxIDs (only on level genus/species) and Accession IDs for your gene within the monophylum.\n",
        "- <b>..._data.csv:</b> corresponds to your fasta file and includes very important data of the sequences\n",
        "<br> \n",
        "<br> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxSVqGIgsHtc",
        "colab_type": "text"
      },
      "source": [
        "#0 Usage\n",
        "This script works with the help of two powerful instutitions: biopython (https://biopython.org/wiki/Documentation) and through a wonderful backdoor to NCBI databases: the Entrez E-utilities service (https://www.ncbi.nlm.nih.gov/books/NBK25497/). If you use the sequence data for scientific purpose (and not only for fun ;-) ), please cite those sources properly (especially biopython requires a citation of Cock et al., 2009!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmS3wSJxmgXn",
        "colab_type": "text"
      },
      "source": [
        "#1 `ncbi_miner`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbx6paTIvMLC",
        "colab_type": "text"
      },
      "source": [
        "At first biopython needs to be installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jhrXDkepk1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6123496d-35d7-43a3-c4db-77d7de25ea88"
      },
      "source": [
        "!pip install biopython"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/01/7e5858a1e54bd0bd0d179cd74654740f07e86fb921a43dd20fb8beabe69d/biopython-1.75-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 11.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 204kB 8.8MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 8.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 8.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 235kB 8.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 8.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 8.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 266kB 8.8MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 8.8MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 307kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 337kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 368kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 399kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 409kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 440kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 471kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 501kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 512kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 532kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 542kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 573kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 604kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 614kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 645kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 665kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 675kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 716kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 737kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 747kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 768kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 798kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 808kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 819kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 829kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 839kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 870kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 880kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 890kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 901kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 911kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 931kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 942kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 952kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 962kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 972kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 983kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.17.4)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8cPOoXm-o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 1.1 The function {display-mode: 'form'}\n",
        "#@markdown Please execute this field. It contains the function `ncbi_miner`, which is the core of this notebook. \n",
        "#@markdown It feeds through the NCBI jungle like the hyperactive caterpillar of a leaf miner.\n",
        "\"\"\"\n",
        "Created on Tue Nov 26 09:29:22 2019\n",
        "\n",
        "@author: Thomsn\n",
        "\"\"\"\n",
        "\n",
        "__author__ = 'thomas m. huber'\n",
        "__email__ = ['thomas.huber@evobio.eu']\n",
        "\n",
        "def ncbi_miner(taxon_query,\n",
        "               gene_name,\n",
        "               gene_length,\n",
        "               my_mail,\n",
        "               coding_sequence = True,\n",
        "               exclude_query = None,\n",
        "               my_API_key = None,\n",
        "               tree_resolution = 'genus',\n",
        "               length_tolerance_percent = 20,\n",
        "               upper_tolerance = 2,\n",
        "               search_limit = 10000,\n",
        "               entries_per_genus = 1,\n",
        "               entries_per_tax = 1,\n",
        "               taxonlist_path = None,\n",
        "               random_mining = False):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    from Bio import SeqIO\n",
        "    from Bio import Entrez\n",
        "    from datetime import datetime\n",
        "    from urllib.error import HTTPError\n",
        "    if random_mining:\n",
        "        from random import shuffle\n",
        "    start_time = datetime.now()\n",
        "\n",
        "\n",
        "    newpath = f'{datetime.now().strftime(\"%Y_%m_%d\")}_{taxon_query}_{gene_name}'\n",
        "    if not os.path.exists(newpath):\n",
        "        os.makedirs(newpath)\n",
        "        print(f'Step 0:\\n >> Directory {newpath} was created.')\n",
        "\n",
        "\n",
        "    gl_lowend = gene_length * (100 - length_tolerance_percent)/100\n",
        "    gl_highend = gene_length * (100 + upper_tolerance * length_tolerance_percent)/100\n",
        "    \n",
        "    tree_resolution = str(tree_resolution).lower()\n",
        "\n",
        "    tax_columns = ['taxID', 'genus', 'epithet', 'entry_UIDs', 'count']\n",
        "\n",
        "    if tree_resolution == 'genus':\n",
        "        taxon_level = 'Genus'\n",
        "    elif tree_resolution == 'species':\n",
        "        taxon_level = 'species'\n",
        "    else:\n",
        "        print(f'Mining data with tree resolution on the taxonomic level \\'{tree_resolution}\\' \\\n",
        "is not possible with this script. Try \\'genus\\' (default) or \\'species\\'.')\n",
        "\n",
        "    if taxonlist_path:\n",
        "        try:\n",
        "            old_taxon_list = pd.read_csv(taxonlist_path)\n",
        "        except FileNotFoundError:\n",
        "            print(f'It was not possible to find input file {taxonlist_path}, please check \\\n",
        "the path and restart \\'ncbi_miner\\'.')\n",
        "            return\n",
        "        else:\n",
        "            if all([(any(old_taxon_list.keys() == i )) for i in tax_columns]):\n",
        "                print(f'The csv-file {taxonlist_path} was loaded. Step 1 will be \\\n",
        "skipped. Follow up steps will use those taxa to search for sequences.')\n",
        "\n",
        "            ### NEW ###\n",
        "                Entrez.email = my_mail\n",
        "                Entrez.api_key = my_API_key\n",
        "                all_taxaIDs = list(old_taxon_list['taxID'])\n",
        "        \n",
        "                progress_criterion = len(all_taxaIDs) // 20\n",
        "                percentage_factor = 20/100\n",
        "        \n",
        "                print(f'Step 2:\\n >> Esearch for gene entries of all species in the taxon {taxon_query}. \\\n",
        "This may take time, so keep the internet connection, chill down, drink a tea. \\n The progress is ...')\n",
        "                taxon_list = pd.DataFrame(columns = tax_columns)\n",
        "                for i, taxon in enumerate(all_taxaIDs):\n",
        "                    k = i + 1\n",
        "                    if (k % progress_criterion) == 1:\n",
        "                        print(f' - {int(i // (progress_criterion*percentage_factor))} % -')\n",
        "                    else:\n",
        "                        pass\n",
        "                    #try:\n",
        "                    #    with Entrez.esummary(db=\"taxonomy\", id=taxon, retmax=search_limit) as handle:\n",
        "                    #      try:\n",
        "                    #        record = Entrez.read(handle)[0]\n",
        "                    #      except IndexError:\n",
        "                    #        print('New Error. No issue!')\n",
        "                    #        break\n",
        "                    #      else:\n",
        "                    #        pass\n",
        "                    #except HTTPError:\n",
        "                    #    print('New Error, we keep running.')\n",
        "                    #else:\n",
        "                    try:\n",
        "                            if coding_sequence:\n",
        "                                query = f'{gene_name}[Gene Name]+txid{str(taxon)}'\n",
        "                            else:\n",
        "                                query = f'{gene_name}+txid{str(taxon)}'\n",
        "                            if exclude_query:\n",
        "                                exclude_string = f'+NOT+{exclude_query}'\n",
        "                                query = f'{query}{exclude_query}'\n",
        "                            with Entrez.esearch(db='nuccore', term=query, retmax=search_limit, sort='pub+date') as handle:\n",
        "                                gene_record = Entrez.read(handle)\n",
        "                    except HTTPError:\n",
        "                            print('New Error, but RUN Forrest RUN!')\n",
        "                    else:\n",
        "                            count = gene_record['Count']\n",
        "                            if count == '0':\n",
        "                                pass\n",
        "                            else:\n",
        "                                taxon_list.loc[i] = [taxon,\n",
        "                                                     old_taxon_list['genus'].iloc[i],\n",
        "                                                     old_taxon_list['epithet'].iloc[i],\n",
        "                                                     gene_record['IdList'],\n",
        "                                                     int(gene_record['Count'])]\n",
        "                taxon_list.to_csv(f'{newpath}/{taxon_query}_{gene_name}_stat.csv')\n",
        "                print(f' >> Done - entry database successfully established. Summary was saved as \\\n",
        "{taxon_query}_{gene_name}_stat.csv')\n",
        "\n",
        "            ### OLD ###\n",
        "\n",
        "            else:\n",
        "                print(f'The input file {taxonlist_path} does not fit with the conditions (header).\\\n",
        "Please change and restart \\'ncbi_miner\\'.')\n",
        "                return\n",
        "\n",
        "    else:\n",
        "        #### > STEP 1 < ####\n",
        "    \n",
        "        Entrez.email = my_mail\n",
        "        Entrez.api_key = my_API_key\n",
        "\n",
        "        try:\n",
        "            with Entrez.esearch(db=\"taxonomy\", term=f'{taxon_query}[orgn]', retmax=search_limit) as handle:\n",
        "                record = Entrez.read(handle)\n",
        "        except HTTPError:\n",
        "            return str('Database error, try later...')\n",
        "        else:\n",
        "            all_taxaIDs = record['IdList']\n",
        "            print('Step 1:\\n >> Done - taxon database successfully established.')\n",
        "        \n",
        "    \n",
        "        #### > STEP 2 < ####\n",
        "    \n",
        "        Entrez.email = my_mail\n",
        "        Entrez.api_key = my_API_key\n",
        "        \n",
        "        progress_criterion = len(all_taxaIDs) // 20\n",
        "        percentage_factor = 20/100\n",
        "        print(f'Step 2:\\n >> Esearch for gene entries of all species in the taxon {taxon_query}. \\\n",
        "This may take time, so keep the internet connection, chill down, drink a tea. \\n The progress is ...')\n",
        "        taxon_list = pd.DataFrame(columns = tax_columns)\n",
        "        for i, taxon in enumerate(all_taxaIDs, 1):\n",
        "            if (i % progress_criterion) == 1:\n",
        "                print(f' - {int(i // (progress_criterion*percentage_factor))} % -')\n",
        "\n",
        "            try:\n",
        "                with Entrez.esummary(db=\"taxonomy\", id=taxon, retmax=search_limit) as handle:\n",
        "                    record = Entrez.read(handle)[0]\n",
        "            except IndexError:\n",
        "                print('New Error. Nemas Problemas!')\n",
        "                break\n",
        "            except HTTPError:\n",
        "                print('New Error, but bro, stay seated, we skip it and keep searching...')\n",
        "            else:\n",
        "                if record['Rank'] == 'species' and record['Genus'] != '':\n",
        "                    try:\n",
        "                        if coding_sequence:\n",
        "                                query = f'{gene_name}[Gene Name]+txid{str(taxon)}'\n",
        "                        else:\n",
        "                                query = f'{gene_name}+txid{str(taxon)}'\n",
        "                        if exclude_query:\n",
        "                                exclude_string = f'+NOT+{exclude_query}'\n",
        "                                query = f'{query}{exclude_query}'\n",
        "                        with Entrez.esearch(db='nuccore', term=query, retmax=search_limit, sort='pub+date') as handle:\n",
        "                            gene_record = Entrez.read(handle)\n",
        "                    except HTTPError:\n",
        "                        print('New Error! But nothing big to worry about.')\n",
        "                    else:\n",
        "                        count = gene_record['Count']\n",
        "                        if count == '0':\n",
        "                            pass\n",
        "                        else:\n",
        "                            taxon_list.loc[i] = [taxon,\n",
        "                                                 record['Genus'],\n",
        "                                                 record['Species'],\n",
        "                                                 gene_record['IdList'],\n",
        "                                                 int(gene_record['Count'])]\n",
        "                else:\n",
        "                    pass\n",
        "        taxon_list.to_csv(f'{newpath}/{taxon_query}_{gene_name}_stat.csv')\n",
        "        print(f' >> Done - entry database successfully established. Summary was saved as \\\n",
        "{taxon_query}_{gene_name}_stat.csv')\n",
        "        \n",
        "    \n",
        "    #### > STEP 3 < ####\n",
        "\n",
        "    print(f'Step 3:\\n >> Efetch for each species of the given genera with the most entries \\\n",
        "for the given gene. This may take some time as well, I would answer some mails in the meantime ;-) \\n The progress is ...')\n",
        "    data_list = pd.DataFrame(columns = ['taxID',\n",
        "                                        'accession',\n",
        "                                        'length',\n",
        "                                        'date',\n",
        "                                        'organism',\n",
        "                                        'authors',\n",
        "                                        'gene_information',\n",
        "                                        'sampling_locality'])\n",
        "    ### NEW ###\n",
        "    if taxon_level == 'Genus':\n",
        "        genera = taxon_list['genus'].unique()\n",
        "    else:\n",
        "        genera = taxon_list['taxID'].unique()\n",
        "    ### OLD ###\n",
        "\n",
        "    progress_criterion = -( -len(genera) // 10)\n",
        "    percentage_factor = 10/100\n",
        "    \n",
        "    \n",
        "    for j, genus_ID in enumerate(genera):\n",
        "        if (j % progress_criterion) == 1:\n",
        "            print(f' - {int(j // (progress_criterion*percentage_factor))} % -')\n",
        "        else:\n",
        "            pass\n",
        "        if taxon_level == 'Genus':\n",
        "          all_species = taxon_list[taxon_list['genus'] == genus_ID]\n",
        "        else:\n",
        "          all_species = taxon_list[taxon_list['taxID'] == genus_ID]\n",
        "        all_species = all_species.sort_values(by=['count'], ascending=False)\n",
        "        if len(list(all_species['entry_UIDs'])) < entries_per_genus:\n",
        "            epg = len(list(all_species['entry_UIDs']))\n",
        "        else:\n",
        "            epg = entries_per_genus\n",
        "        for entry in list(range(epg)):\n",
        "        ### NEW ###\n",
        "            entry_list = list(all_species['entry_UIDs'])[entry]\n",
        "            if random_mining:\n",
        "                shuffle(entry_list)\n",
        "        ### OLD ###\n",
        "            Entrez.email = my_mail\n",
        "            Entrez.api_key = my_API_key\n",
        "            entry_counter = 0\n",
        "            for i, acc_id in enumerate(entry_list):\n",
        "                try:\n",
        "                    with Entrez.efetch(db=\"nuccore\", id=acc_id, retmode='text', rettype=\"gb\") as handle:\n",
        "                        record = SeqIO.read(handle, \"genbank\")\n",
        "                except HTTPError:\n",
        "                    print('New Error, but chill down, everything is soft')\n",
        "                else:\n",
        "                    if gl_lowend < len(record) < gl_highend:\n",
        "                        features = record.features\n",
        "                        filterframe = [x.type == 'gene' for x in features]\n",
        "                        if all(filterframe) == False:\n",
        "                            filterframe = [x.type != 'source' for x in features]\n",
        "                            keyword = 'product'\n",
        "                        else:\n",
        "                            keyword = 'gene'\n",
        "                        gene_features = [x for i, x in enumerate(features) if filterframe[i]==True]\n",
        "                        gene_info = [(x.qualifiers.get(keyword))[0] for x in gene_features]\n",
        "                        sample_locality = features[0].qualifiers.get('country')\n",
        "                        data_list.loc[f'{j+1}_{record.id}'] = [genus_ID,\n",
        "                                            record.id,\n",
        "                                            len(record),\n",
        "                                            record.annotations['date'],\n",
        "                                            record.annotations['organism'],\n",
        "                                            record.annotations['authors'],\n",
        "                                            gene_info,\n",
        "                                            sample_locality]\n",
        "                        with open(f'{newpath}/{taxon_query}_{gene_name}.fasta', 'a') as finalfasta:\n",
        "                            rawseq = str(record.seq)\n",
        "                            if taxon_level == 'species':\n",
        "                                fasta_head = str(record.annotations['organism'])\n",
        "                                fasta_head = fasta_head.replace(' ', '_')\n",
        "                            else:\n",
        "                                fasta_head = genus_ID\n",
        "                            if entries_per_tax == 1 and entries_per_genus == 1:\n",
        "                                finalfasta.write(f'>{fasta_head}\\n')\n",
        "                            else:\n",
        "                                finalfasta.write(f'>{fasta_head}_{record.id}\\n')\n",
        "                            finalfasta.write(f'{rawseq}\\n\\n')\n",
        "                ### NEW ###\n",
        "                        entry_counter += 1\n",
        "                        if entry_counter == entries_per_tax:\n",
        "                            break\n",
        "                        else:\n",
        "                            pass\n",
        "                ### OLD ###\n",
        "                    else:\n",
        "                        pass\n",
        "    data_list.to_csv(f'{newpath}/{taxon_query}_{gene_name}_data.csv')\n",
        "    print(f' >> Done - most recent fasta sequences were collected and successfully concatenated. \\\n",
        "It was saved in the file {taxon_query}_{gene_name}.fasta and is proove for nexus conversion. \\\n",
        "Summary of used sequences was saved as {taxon_query}_{gene_name}_data.csv.')\n",
        "    stop_time = datetime.now()\n",
        "    process_time = stop_time - start_time\n",
        "    print(f' >> NCBI mining finished. It took {process_time.seconds // 60} min, \\\n",
        "{process_time.seconds % 60} sec. The files are stored in the directory {newpath}.')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpyNsbnYmkfB",
        "colab_type": "text"
      },
      "source": [
        "#2 Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJSMMe8jmqox",
        "colab_type": "text"
      },
      "source": [
        "##2.1 Mandatory arguments for search\n",
        "Please enter your monophylum as query and run the block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xKON2cEpWP9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#{display-mode: 'form'}\n",
        "#@markdown Name of monophyletic taxon:\n",
        "taxon_query = 'Gentianaceae' #@param {type:\"string\"}\n",
        "#@markdown Name of gene:\n",
        "gene_name = 'matk' #@param {type:\"string\"}\n",
        "#@markdown Estimate of gene length (check at NCBI, pubmed, ...):\n",
        "gene_length = 700 #@param {type:\"number\"}\n",
        "#@markdown Enter your mail adress (mandatory for NCBI search):\n",
        "my_mail = 'antilope.booty@evo.com' #@param {type:\"string\"}\n",
        "coding_sequence = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpcmQWallgIg",
        "colab_type": "text"
      },
      "source": [
        "##2.2 Optional arguments for search\n",
        "The following parameters can be adjusted. Please run the block afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k6D-CJuAu-E",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#{display-mode: 'form'}\n",
        "#@markdown Enter your NCBI API key (increases search pace by factor ~ 3). Read more here : https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/\n",
        "#@markdown <br/>(!) You will need to set it within quotation marks (e.g. 'AZNE192930N8D...NDJE9D0').\n",
        "my_API_key =  None#@param {type:\"raw\"}\n",
        "#@markdown Which resolution should your tree have (default: Genus)? i.e. taxonomic level of external branches\n",
        "tree_resolution = 'genus' #@param ['genus', 'species']\n",
        "#@markdown Tolerance (in percent) of gene length for the retrieved sequences setting lower limit (default: 20).\n",
        "length_tolerance_percent = 20 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "#@markdown Factor for tolerance setting the upper limit to retrieve sequences.\n",
        "upper_tolerance = 2 #@param {type:\"number\"}\n",
        "#@markdown Enter the limit of retrieved results per search (default: 10000).\n",
        "search_limit = 10000 #@param {type:\"slider\", min:1, max:10000, step:1}\n",
        "#@markdown How many species per genus do you want to retrieve? The species within a genus will be ranked after count of entries for the given gene.\n",
        "entries_per_genus = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "#@markdown How many entries do you want to retrieve per species/taxon?\n",
        "entries_per_tax = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "#@markdown Usually the results will be sorted by increasing age, so the most recent entries should be retrieved. Do you want to change it to random order?\n",
        "random_mining = False #@param {type:\"boolean\"}\n",
        "taxonlist_path = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9o6IdNeFFYc",
        "colab_type": "text"
      },
      "source": [
        "##(2.3 Upload of accession list as csv)\n",
        "Do you already have a set of selected accession IDs as a result of a previous use of lumberjack (i.e. deforestation) and you want to use it for a new search (e.g. different genes)? Then you should upload it here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7ZRW1-oFEHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title --> Upload here! <-- {display-mode: 'form'}\n",
        "from google.colab import files\n",
        "uploaded = files.upload() \n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  taxonlist_path = fn\n",
        "  print(f'Upload successful, {fn} will be used in the following ncbi_miner session')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cptmqa2FlQTL",
        "colab_type": "text"
      },
      "source": [
        "#3 Let's go!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mGkjHEioV05",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@markdown On the left you can see how the function is called. Run it, to conduct the deforestation of the NCBI jungle.\n",
        "ncbi_miner(taxon_query = taxon_query,\n",
        "               gene_name = gene_name,\n",
        "               gene_length = gene_length,\n",
        "               my_mail = my_mail,\n",
        "               my_API_key = my_API_key,\n",
        "               tree_resolution = tree_resolution,\n",
        "               length_tolerance_percent = length_tolerance_percent,\n",
        "               upper_tolerance = upper_tolerance,\n",
        "               search_limit = search_limit,\n",
        "               entries_per_genus = entries_per_genus,\n",
        "               entries_per_tax = entries_per_tax,\n",
        "               taxonlist_path = taxonlist_path,\n",
        "               random_mining = random_mining)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0DLOibEjy3w",
        "colab_type": "text"
      },
      "source": [
        "#4 ReSearch with different gene but same accessions\n",
        "This block uses the data which was previously produced on the server. If you want to upload the file you use, change `gene_name`and `gene_length` in 2.1, upload the file in 2.3 and finally run `ncbi_miner` in 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Zg6ODdjyCU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#{display-mode: 'form'}\n",
        "#@markdown What is the name of your new gene?\n",
        "new_gene_name = 'rbcl' #@param {type:\"string\"}\n",
        "#@markdown Estimate the length of your new gene:\n",
        "new_gene_length = 750 #@param {type:\"number\"}\n",
        "#@markdown When did you perform the search for accessions for the old gene?\n",
        "date_of_old_search = \"2019-12-12\"#@param {type:\"date\"}\n",
        "date_underscore = date_of_old_search.replace('-', '_')\n",
        "\n",
        "old_file = f'{date_underscore}_{taxon_query}_{gene_name}/{taxon_query}_{gene_name}_stat.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff0X95nNmvmz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#{display-mode: 'form'}\n",
        "#@markdown Run the search with new gene - old accessions (same parameters).\n",
        "ncbi_miner(taxon_query = taxon_query,\n",
        "               gene_name = new_gene_name,\n",
        "               gene_length = new_gene_length,\n",
        "               my_mail = my_mail,\n",
        "               my_API_key = my_API_key,\n",
        "               tree_resolution = tree_resolution,\n",
        "               length_tolerance_percent = length_tolerance_percent,\n",
        "               upper_tolerance = upper_tolerance,\n",
        "               search_limit = search_limit,\n",
        "               entries_per_genus = entries_per_genus,\n",
        "               entries_per_tax = entries_per_tax,\n",
        "               taxonlist_path = old_file,\n",
        "               random_mining = random_mining)\n",
        "#@markdown ---\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIqrAl76mPsE",
        "colab_type": "text"
      },
      "source": [
        "#5 Download\n",
        "After producing your data, you can download it all together. Date will be assumed to be today."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nonflVdjs_Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 5.1 Zip file for (Re)Search* {display-mode: 'form'}\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "from google.colab import files\n",
        "#@markdown When did you perform the (re)search you want to download?\n",
        "date_of_search = \"2019-12-12\"#@param {type:\"date\"}\n",
        "date_uscore = date_of_search.replace('-', '_')\n",
        "#@markdown Search (3.) or  ReSearch (4.)?\n",
        "option = 'search' #@param ['search', 'research']\n",
        "\n",
        "if option == 'search':\n",
        "  zip_gene = gene_name\n",
        "else:\n",
        "  zip_gene = new_gene_name\n",
        "directory = f'{date_uscore}_{taxon_query}_{zip_gene}'\n",
        "folder = shutil.make_archive(directory, 'zip', directory)\n",
        "files.download(folder)\n",
        "\n",
        "\n",
        "#@markdown <br><br>The data you produced will be stored into a ZIP file and downloaded. <br> <br> *) Search and ReSearch store their files in different folders. Those would need to be downloaded subsequently.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_BsxlXzuqvE",
        "colab_type": "text"
      },
      "source": [
        "#References\n",
        "<i>Cock PA, Antao T, Chang JT, Chapman BA, Cox CJ, Dalke A, Friedberg I, Hamelryck T, Kauff F, Wilczynski B and de Hoon MJL (2009):</i> Biopython - freely available Python tools for computational molecular biology and bioinformatics. Bioinformatics, 25, 1422-1423"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkQoOeLJtEQB",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "Thank you for using the NCBI lumberjack, have fun with the sequences!<br>\n",
        "`Questions: thomas.huber@evobio.eu`"
      ]
    }
  ]
}